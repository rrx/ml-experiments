{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Experiments using CNN\n",
    "\n",
    "Using a variety of data sources, attempt to detect facial features and identify subjects.  We attemp to use pre-weighted VGG16 from Keras.\n",
    "\n",
    "http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
    "\n",
    "http://www.face-rec.org/databases/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Flatten, Lambda, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.applications import vgg16\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_45 (Convolution2D) (None, 32, 100, 100)  320         convolution2d_input_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_25 (MaxPooling2D)   (None, 32, 50, 50)    0           convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 32, 50, 50)    9248        maxpooling2d_25[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 32, 50, 50)    0           convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 64, 50, 50)    18496       dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_26 (MaxPooling2D)   (None, 64, 25, 25)    0           convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 64, 25, 25)    36928       maxpooling2d_26[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 64, 25, 25)    0           convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 40000)         0           dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 2)             80002       flatten_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 144994\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model to detect if the person has glasses or not\n",
    "input_shape = (1, 100, 100)\n",
    "model = Sequential(name='encoder')\n",
    "model.add(Conv2D(32, 3, 3, input_shape=input_shape, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "model.add(Conv2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "#model.load_weights('models/convolutional_recognizer_2.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, gen=ImageDataGenerator(height_shift_range=10, horizontal_flip=True), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "        return gen.flow_from_directory(path, target_size=(100,100), color_mode='grayscale',\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', cmap='jet')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(\"yalefaces/features/spectacles\", batch_size=30)\n",
    "images, labels = batches.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1s - loss: 0.4503 - acc: 0.7667\n",
      "Epoch 2/10\n",
      "1s - loss: 0.4330 - acc: 0.7667\n",
      "Epoch 3/10\n",
      "1s - loss: 0.4447 - acc: 0.7667\n",
      "Epoch 4/10\n",
      "1s - loss: 0.4470 - acc: 0.7667\n",
      "Epoch 5/10\n",
      "1s - loss: 0.4380 - acc: 0.7667\n",
      "Epoch 6/10\n",
      "1s - loss: 0.4681 - acc: 0.7667\n",
      "Epoch 7/10\n",
      "1s - loss: 0.4616 - acc: 0.7667\n",
      "Epoch 8/10\n",
      "1s - loss: 0.4535 - acc: 0.7667\n",
      "Epoch 9/10\n",
      "1s - loss: 0.4523 - acc: 0.7667\n",
      "Epoch 10/10\n",
      "1s - loss: 0.4508 - acc: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf5e42bb10>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "model.fit(images/255., labels, nb_epoch=nb_epoch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_49 (Convolution2D) (None, 32, 100, 100)  320         convolution2d_input_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 32, 50, 50)    0           convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 32, 50, 50)    9248        maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 32, 50, 50)    0           convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_51 (Convolution2D) (None, 64, 50, 50)    18496       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_28 (MaxPooling2D)   (None, 64, 25, 25)    0           convolution2d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_52 (Convolution2D) (None, 64, 25, 25)    36928       maxpooling2d_28[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_29 (MaxPooling2D)   (None, 64, 13, 13)    0           convolution2d_52[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 64, 13, 13)    0           maxpooling2d_29[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 10816)         0           dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 40)            432680      flatten_13[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 497672\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model for recognizing a set of 40 individuals\n",
    "input_shape = (1, 100, 100)\n",
    "faces_model = Sequential()\n",
    "faces_model.add(Conv2D(32, 3, 3, input_shape=input_shape, activation='relu', border_mode='same'))\n",
    "faces_model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "faces_model.add(Conv2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "faces_model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "faces_model.add(Conv2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "faces_model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "faces_model.add(Conv2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "faces_model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "faces_model.add(Dropout(0.25))\n",
    "faces_model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "faces_model.add(Dense(40, activation='softmax'))\n",
    "faces_model.summary()\n",
    "#model.load_weights('models/convolutional_recognizer_2.weights.h5')\n",
    "faces_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 40 classes.\n",
      "Found 80 images belonging to 40 classes.\n",
      "Epoch 1/10\n",
      "9s - loss: 0.1049 - acc: 0.9754\n",
      "Epoch 2/10\n",
      "9s - loss: 0.1019 - acc: 0.9757\n",
      "Epoch 3/10\n",
      "9s - loss: 0.0989 - acc: 0.9755\n",
      "Epoch 4/10\n",
      "8s - loss: 0.0967 - acc: 0.9755\n",
      "Epoch 5/10\n",
      "8s - loss: 0.0961 - acc: 0.9759\n",
      "Epoch 6/10\n",
      "9s - loss: 0.0938 - acc: 0.9762\n",
      "Epoch 7/10\n",
      "8s - loss: 0.0909 - acc: 0.9763\n",
      "Epoch 8/10\n",
      "9s - loss: 0.0891 - acc: 0.9769\n",
      "Epoch 9/10\n",
      "9s - loss: 0.0861 - acc: 0.9766\n",
      "Epoch 10/10\n",
      "9s - loss: 0.0847 - acc: 0.9771\n",
      "Loss: 0.08386 Accuracy: 0.97625\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(\"att_faces\", batch_size=400)\n",
    "test_batches = get_batches(\"att_faces_test\", batch_size=40)\n",
    "nb_epoch = 10\n",
    "nb_val_samples=test_batches.N\n",
    "X, Y = batches.next()\n",
    "faces_model.fit(X/255., Y, nb_epoch=nb_epoch, verbose=2)\n",
    "X_test, Y_test = test_batches.next()\n",
    "loss, acc = faces_model.test_on_batch(X_test/255., Y_test)\n",
    "print(\"Loss: %.5f Accuracy: %.5f\" % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
